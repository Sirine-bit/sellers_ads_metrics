"""
Client MongoDB unifiÃ© pour toutes les opÃ©rations
GÃ¨re: stores, ads_metrics (Phase 1 mapping + Phase 2 analysis)
"""
from pymongo import MongoClient, ASCENDING, DESCENDING
from pymongo.errors import ConnectionFailure, DuplicateKeyError
from typing import Dict, Any, List, Optional
from datetime import datetime
from bson import ObjectId
import os
from src.utils.logger import setup_logger

logger = setup_logger(__name__)


class MongoDBClient:
    """Client MongoDB unifiÃ© pour Converty"""
    
    def __init__(self, connection_string: str = None):
        """
        Initialiser la connexion MongoDB
        
        Args:
            connection_string: URI MongoDB (dÃ©faut: 127.0.0.1:27017)
        """
        self.connection_string = connection_string or os.getenv(
            'MONGODB_URI', 
            'mongodb://127.0.0.1:27017/?directConnection=true'
        )
        self.client = None
        self.db = None
        self._connect()
    
    def _connect(self):
        """Ã‰tablir la connexion Ã  MongoDB"""
        try:
            self.client = MongoClient(self.connection_string)
            # Test de connexion
            self.client.admin.command('ping')
            
            # SÃ©lectionner la base de donnÃ©es
            self.db = self.client['converty']
            
            logger.info("âœ… ConnectÃ© Ã  MongoDB (converty)")
            
            # CrÃ©er les indexes
            self._create_indexes()
            
        except ConnectionFailure as e:
            logger.error(f"âŒ Ã‰chec de connexion MongoDB: {e}")
            raise
    
    def _create_indexes(self):
        """CrÃ©er tous les indexes nÃ©cessaires"""
        try:
            collection = self.db['ads_metrics']
            
            # Index pour Phase 1 (mapping)
            collection.create_index('client_id', unique=False, name='idx_client_id')
            collection.create_index('processing_status', name='idx_status')
            collection.create_index('timestamp', name='idx_timestamp')
            collection.create_index(
                [('client_id', ASCENDING), ('type', ASCENDING)],
                name='idx_client_type'
            )
            
            # Index pour Phase 2 (analysis/report)
            collection.create_index([
                ('client_slug', ASCENDING),
                ('analyzed_at', DESCENDING)
            ], name='idx_client_analyzed')
            
            collection.create_index('store_id', name='idx_store')
            collection.create_index('domain', name='idx_domain')
            collection.create_index(
                [('analyzed_at', DESCENDING)], 
                name='idx_analyzed_desc'
            )
            
            # Index composite pour type de document
            collection.create_index(
                [('type', ASCENDING), ('timestamp', DESCENDING)],
                name='idx_type_timestamp'
            )
            
            logger.info("âœ… Indexes MongoDB crÃ©Ã©s/vÃ©rifiÃ©s")
        except Exception as e:
            logger.warning(f"âš ï¸ Erreur crÃ©ation indexes: {e}")
    
    # ========================================================================
    # PHASE 1: DISCOVERY & MAPPING
    # ========================================================================
    
    def save_mapping(self, mapping: Dict, processing_metadata: Dict = None) -> bool:
        """
        Sauvegarder un mapping de Phase 1 dans ads_metrics
        
        Args:
            mapping: RÃ©sultat du mapping (format SiteMapper)
            processing_metadata: MÃ©tadonnÃ©es du traitement
        
        Returns:
            True si succÃ¨s, False sinon
        """
        try:
            client_id = mapping['client_id']
            
            # Calculer le total d'ads pour dÃ©terminer le statut
            total_ads = sum(m['total_ads'] for m in mapping.get('mappings', []))
            is_active = mapping.get('is_active', total_ads >= 5)
            
            # PrÃ©parer le document
            document = {
                'client_id': client_id,
                'type': 'mapping',  # Type Phase 1
                'timestamp': datetime.now(),
                'processing_status': 'completed',
                
                # ğŸ¯ STATUT ACTIVITÃ‰ (simplifiÃ©)
                'status': 'active' if is_active else 'inactive',
                'is_active': is_active,
                'phase2_recommendation': 'PROCESS' if is_active else 'SKIP',
                
                # Statistiques globales
                'stats': {
                    'total_sites': len(mapping.get('mappings', [])),
                    'total_ads': total_ads,
                    'total_fb_pages': sum(len(m['fb_pages']) for m in mapping.get('mappings', [])),
                    'sites_with_ads': sum(1 for m in mapping.get('mappings', []) if m['total_ads'] > 0),
                    'sites_with_pages': sum(1 for m in mapping.get('mappings', []) if m['fb_pages'])
                },
                
                # DÃ©tails par site
                'sites_mapping': [],
                
                # MÃ©tadonnÃ©es de traitement
                'processing_metadata': processing_metadata or {}
            }
            
            # Transformer les mappings
            for site_mapping in mapping.get('mappings', []):
                site_data = {
                    'site': site_mapping['site'],
                    'total_ads': site_mapping['total_ads'],
                    'discovery_timestamp': site_mapping.get('timestamp'),
                    
                    # Pages Facebook
                    'fb_pages': [
                        {
                            'page_id': page['page_id'],
                            'page_name': page['page_name'],
                            'page_url': page['page_url'],
                            'ads_count': page['ads_count'],
                            'confidence': page['confidence'],
                            'sample_ads': page.get('sample_ads', [])
                        }
                        for page in site_mapping.get('fb_pages', [])
                    ],
                    
                    # MÃ©tadonnÃ©es
                    'metadata': {
                        'has_ads': site_mapping['total_ads'] > 0,
                        'has_fb_pages': len(site_mapping.get('fb_pages', [])) > 0,
                        'best_match_confidence': max(
                            [p['confidence'] for p in site_mapping.get('fb_pages', [])],
                            default=0
                        )
                    }
                }
                
                document['sites_mapping'].append(site_data)
            
            # Upsert (mise Ã  jour ou insertion)
            result = self.db.ads_metrics.update_one(
                {'client_id': client_id, 'type': 'mapping'},
                {'$set': document},
                upsert=True
            )
            
            if result.upserted_id:
                logger.info(f"âœ… Nouveau mapping crÃ©Ã© pour {client_id}")
            else:
                logger.info(f"âœ… Mapping mis Ã  jour pour {client_id}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur sauvegarde mapping pour {mapping.get('client_id')}: {e}")
            return False
    
    def mark_mapping_as_failed(self, client_id: str, error: str, 
                               processing_metadata: Dict = None) -> bool:
        """Marquer un mapping comme Ã©chouÃ© (enregistrÃ© comme inactive)"""
        try:
            document = {
                'client_id': client_id,
                'type': 'mapping',
                'timestamp': datetime.now(),
                'processing_status': 'failed',
                # ğŸ¯ SimplifiÃ© : juste inactive, pas de dÃ©tails d'erreur
                'status': 'inactive',
                'is_active': False,
                'phase2_recommendation': 'SKIP',
                'processing_metadata': processing_metadata or {},
                'stats': {
                    'total_sites': 0,
                    'total_ads': 0,
                    'total_fb_pages': 0
                },
                'sites_mapping': []
            }
            
            result = self.db.ads_metrics.update_one(
                {'client_id': client_id, 'type': 'mapping'},
                {'$set': document},
                upsert=True
            )
            
            logger.info(f"âŒ Ã‰chec mapping enregistrÃ© pour {client_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur enregistrement Ã©chec pour {client_id}: {e}")
            return False
    
    def get_mapping(self, client_id: str) -> Optional[Dict]:
        """RÃ©cupÃ©rer le mapping d'un client"""
        try:
            return self.db.ads_metrics.find_one({
                'client_id': client_id,
                'type': 'mapping'
            })
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration mapping pour {client_id}: {e}")
            return None
    
    def is_mapping_completed(self, client_id: str) -> bool:
        """VÃ©rifier si le mapping est complÃ©tÃ© avec succÃ¨s"""
        try:
            doc = self.db.ads_metrics.find_one({
                'client_id': client_id,
                'type': 'mapping',
                'processing_status': 'completed'
            })
            return doc is not None
        except Exception as e:
            logger.error(f"âŒ Erreur vÃ©rification mapping pour {client_id}: {e}")
            return False
    
    # ========================================================================
    # PHASE 2: ANALYSIS & REPORTING
    # ========================================================================
    
    def save_ad_metrics(
        self, 
        client_slug: str,
        domain: str,
        report: Dict[str, Any],
        store_id: ObjectId = None
    ) -> Optional[str]:
        """
        Sauvegarder les mÃ©triques publicitaires (Phase 2)
        
        Args:
            client_slug: Slug du client
            domain: Domaine principal
            report: Rapport de Phase 2
            store_id: ID du store (optionnel)
            
        Returns:
            ID du document crÃ©Ã© ou None
        """
        try:
            # RÃ©cupÃ©rer store_id si non fourni
            if not store_id:
                store = self.get_store_by_slug(client_slug)
                if store:
                    store_id = store['_id']
            
            # PrÃ©parer le document
            metrics_doc = {
                'client_slug': client_slug,
                'client_id': client_slug,  # Alias pour compatibilitÃ©
                'store_id': store_id,
                'domain': domain,
                'type': 'report',  # Type Phase 2
                'analyzed_at': datetime.fromisoformat(report['analyzed_at']),
                'timestamp': datetime.utcnow(),
                
                # MÃ©triques globales
                'metrics': report['global_stats'],
                
                # Pages Facebook
                'facebook_pages': [
                    {
                        'page_id': page['page_id'],
                        'page_name': page['page_name'],
                        'total_ads': page['total_ads'],
                        'converty_ads': page['converty_ads'],
                        'concurrent_ads': page['concurrent_ads'],
                        'converty_ratio': page['converty_ratio']
                    }
                    for page in report['page_details']
                ],
                
                # Concurrents
                'competitors': report['top_competitors'],
                
                # MÃ©tadonnÃ©es
                'version': '2.0',
                'created_at': datetime.utcnow(),
                'updated_at': datetime.utcnow()
            }
            
            # InsÃ©rer dans MongoDB
            result = self.db.ads_metrics.insert_one(metrics_doc)
            
            logger.info(f"âœ… MÃ©triques Phase 2 sauvegardÃ©es pour {client_slug} (ID: {result.inserted_id})")
            
            return str(result.inserted_id)
            
        except Exception as e:
            logger.error(f"âŒ Erreur sauvegarde mÃ©triques Phase 2 {client_slug}: {e}")
            return None
    
    def save_ads_metrics(self, store_slug: str, metrics_data: Dict[str, Any]):
        """
        Sauvegarder les mÃ©triques publicitaires (format simplifiÃ©)
        Alias pour compatibilitÃ© avec l'ancien code
        
        Args:
            store_slug: Identifiant du magasin
            metrics_data: DonnÃ©es des mÃ©triques
        """
        try:
            mongo_doc = {
                'store_slug': store_slug,
                'client_id': store_slug,
                'type': 'report',
                'timestamp': datetime.utcnow(),
                'total_ads': metrics_data.get('total_ads', 0),
                'stats': metrics_data.get('stats', {}),
                'pages': metrics_data.get('pages', []),
                'ads_details': metrics_data.get('ads_details', []),
                'summary': {
                    'total_analyzed': metrics_data.get('total_ads', 0),
                    'converty_ads': sum(1 for ad in metrics_data.get('ads_details', []) 
                                       if ad.get('classification') == 'CONVERTY'),
                    'competitor_ads': sum(1 for ad in metrics_data.get('ads_details', []) 
                                         if ad.get('classification') == 'CONCURRENT'),
                    'unknown_ads': sum(1 for ad in metrics_data.get('ads_details', []) 
                                      if ad.get('classification') == 'UNKNOWN')
                }
            }
            
            result = self.db.ads_metrics.insert_one(mongo_doc)
            
            logger.info(f"âœ… MÃ©triques sauvegardÃ©es pour {store_slug} (ID: {result.inserted_id})")
            return result.inserted_id
        except Exception as e:
            logger.error(f"âŒ Erreur sauvegarde mÃ©triques pour {store_slug}: {e}")
            raise
    
    # ========================================================================
    # STORES - Gestion des magasins
    # ========================================================================
    
    def get_all_stores(self) -> List[Dict[str, Any]]:
        """RÃ©cupÃ©rer tous les magasins"""
        try:
            stores = list(self.db.stores.find({}))
            logger.info(f"âœ… {len(stores)} magasins rÃ©cupÃ©rÃ©s")
            return stores
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration magasins: {e}")
            raise
    
    def get_store_by_slug(self, slug: str) -> Optional[Dict]:
        """RÃ©cupÃ©rer un store par son slug"""
        try:
            store = self.db.stores.find_one({'slug': slug})
            return store
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration store {slug}: {e}")
            return None
    
    # ========================================================================
    # REQUÃŠTES & STATISTIQUES
    # ========================================================================
    
    def get_latest_metrics(self, client_slug: str) -> Optional[Dict]:
        """RÃ©cupÃ©rer les derniÃ¨res mÃ©triques (Phase 2)"""
        try:
            metrics = self.db.ads_metrics.find_one(
                {'client_slug': client_slug, 'type': 'report'},
                sort=[('analyzed_at', DESCENDING)]
            )
            return metrics
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration mÃ©triques {client_slug}: {e}")
            return None
    
    def get_metrics_history(
        self, 
        client_slug: str, 
        limit: int = 10
    ) -> List[Dict]:
        """RÃ©cupÃ©rer l'historique des mÃ©triques"""
        try:
            cursor = self.db.ads_metrics.find(
                {'client_slug': client_slug, 'type': 'report'}
            ).sort('analyzed_at', DESCENDING).limit(limit)
            
            return list(cursor)
        except Exception as e:
            logger.error(f"âŒ Erreur historique {client_slug}: {e}")
            return []
    
    def get_all_mappings(self, status: str = None) -> List[Dict]:
        """RÃ©cupÃ©rer tous les mappings (Phase 1)"""
        try:
            query = {'type': 'mapping'}
            if status:
                query['processing_status'] = status
            
            return list(self.db.ads_metrics.find(query).sort('timestamp', -1))
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration mappings: {e}")
            return []
    
    def get_mapping_statistics(self) -> Dict:
        """Obtenir des statistiques sur les mappings"""
        try:
            pipeline = [
                {'$match': {'type': 'mapping'}},
                {
                    '$group': {
                        '_id': '$processing_status',
                        'count': {'$sum': 1},
                        'total_ads': {'$sum': '$stats.total_ads'},
                        'total_fb_pages': {'$sum': '$stats.total_fb_pages'}
                    }
                }
            ]
            
            results = list(self.db.ads_metrics.aggregate(pipeline))
            
            stats = {
                'total_clients': self.db.ads_metrics.count_documents({'type': 'mapping'}),
                'by_status': {r['_id']: r for r in results},
                'last_update': None
            }
            
            # Dernier timestamp
            last_doc = self.db.ads_metrics.find_one(
                {'type': 'mapping'},
                sort=[('timestamp', -1)]
            )
            if last_doc:
                stats['last_update'] = last_doc.get('timestamp')
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ Erreur calcul statistiques: {e}")
            return {}
    
    def delete_mapping(self, client_id: str) -> bool:
        """Supprimer le mapping d'un client"""
        try:
            result = self.db.ads_metrics.delete_one({
                'client_id': client_id,
                'type': 'mapping'
            })
            if result.deleted_count > 0:
                logger.info(f"ğŸ—‘ï¸ Mapping supprimÃ© pour {client_id}")
                return True
            return False
        except Exception as e:
            logger.error(f"âŒ Erreur suppression mapping pour {client_id}: {e}")
            return False
    
    # ========================================================================
    # UTILITAIRES
    # ========================================================================
    
    def close(self):
        """Fermer la connexion MongoDB"""
        if self.client:
            self.client.close()
            logger.info("ğŸ”Œ Connexion MongoDB fermÃ©e")