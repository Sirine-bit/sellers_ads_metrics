"""
Collecteur de publicit√©s par domaine - AVEC FILTRAGE STRICT + CACHE
"""
from typing import List, Dict, Any
from src.clients.apify_client import ApifyFacebookAdsClient
from src.utils.logger import setup_logger
from src.utils.simple_cache import SimpleCache

logger = setup_logger(__name__)


class AdsCollector:
    """Collecte UNIQUEMENT les publicit√©s li√©es au domaine donn√© avec cache"""
    
    def __init__(self, use_cache: bool = True, cache_ttl_days: int = 7):
        """
        Args:
            use_cache: Activer le cache (d√©faut: True)
            cache_ttl_days: Dur√©e de validit√© du cache en jours (d√©faut: 7)
        """
        self.apify_client = ApifyFacebookAdsClient()
        self.use_cache = use_cache
        self.cache = SimpleCache(ttl_days=cache_ttl_days) if use_cache else None
    
    def collect_ads_for_domain(
        self, 
        domain: str,
        force_refresh: bool = False
    ) -> List[Dict[str, Any]]:
        """
        Collecter UNIQUEMENT les publicit√©s qui contiennent le domaine exact
        
        Args:
            domain: Domaine √† analyser (ex: "ravino.converty.shop")
            force_refresh: Forcer le re-scraping m√™me si en cache
            
        Returns:
            Liste des publicit√©s FILTR√âES (uniquement celles avec le domaine)
        """
        logger.info(f"üìä Collecte des ads POUR LE DOMAINE: {domain}")
        
        # 1. V√©rifier le cache d'abord (si activ√©)
        if self.use_cache and not force_refresh:
            cached_ads = self.cache.get(domain)
            if cached_ads is not None:
                # Cache HIT - filtrage d√©j√† fait
                return cached_ads
        
        # 2. Cache MISS - collecter depuis Apify
        logger.info(f"üåê Scraping Apify pour {domain}...")
        all_ads = self.apify_client.search_ads_by_domain(domain)
        logger.info(f"üì• {len(all_ads)} ads brutes r√©cup√©r√©es")
        
        # 3. Filtrer STRICTEMENT
        filtered_ads = self._filter_ads_strictly_by_domain(all_ads, domain)
        logger.info(f"‚úÖ {len(filtered_ads)} ads FILTR√âES pour {domain}")
        
        # 4. Sauvegarder dans le cache
        if self.use_cache:
            self.cache.set(domain, filtered_ads)
        
        return filtered_ads
    
    def _filter_ads_strictly_by_domain(
        self, 
        ads: List[Dict[str, Any]], 
        target_domain: str
    ) -> List[Dict[str, Any]]:
        """
        Filtrer STRICTEMENT les ads pour garder uniquement celles avec le domaine exact
        """
        filtered_ads = []
        
        for ad in ads:
            if self._ad_contains_domain(ad, target_domain):
                filtered_ads.append(ad)
                logger.debug(f"‚úì Ad {ad.get('ad_archive_id')} contient {target_domain}")
            else:
                logger.debug(f"‚úó Ad {ad.get('ad_archive_id')} ignor√©e (pas de domaine {target_domain})")
        
        return filtered_ads
    
    def _ad_contains_domain(self, ad: Dict[str, Any], target_domain: str) -> bool:
        """
        V√©rifier si l'ad contient le domaine exact dans ses URLs
        """
        snapshot = ad.get('snapshot', {})
        
        # S√©curit√© : si snapshot est None
        if not snapshot:
            return False
        
        # 1. V√©rifier le lien principal
        link_url = snapshot.get('link_url') or ''  # Protection contre None
        if target_domain in link_url:
            return True
        
        # 2. V√©rifier dans les cards (carousel)
        cards = snapshot.get('cards') or []  # Protection contre None
        for card in cards:
            if not card:  # Protection contre None
                continue
            card_link = card.get('link_url') or ''
            if target_domain in card_link:
                return True
        
        # 3. V√©rifier la caption
        caption = snapshot.get('caption') or ''  # Protection contre None
        if target_domain in caption:
            return True
        
        return False